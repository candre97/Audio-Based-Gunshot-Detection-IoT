{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Classifying Urban sounds using Deep Learning\n",
    "\n",
    "## 4 Model Refinement "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Load Preprocessed data "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "no stored variable x_train\n",
      "no stored variable x_test\n",
      "no stored variable y_train\n",
      "no stored variable y_test\n",
      "no stored variable yy\n",
      "no stored variable le\n"
     ]
    }
   ],
   "source": [
    "# retrieve the preprocessed data from previous notebook\n",
    "\n",
    "%store -r x_train \n",
    "%store -r x_test \n",
    "%store -r y_train \n",
    "%store -r y_test \n",
    "%store -r yy \n",
    "%store -r le"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Model refinement\n",
    "\n",
    "In our inital attempt, we were able to achieve a Classification Accuracy score of: \n",
    "\n",
    "* Training data Accuracy:  92.3% \n",
    "* Testing data Accuracy:  87% \n",
    "\n",
    "We will now see if we can improve upon that score using a Convolutional Neural Network (CNN). "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Feature Extraction refinement \n",
    "\n",
    "In the prevous feature extraction stage, the MFCC vectors would vary in size for the different audio files (depending on the samples duration). \n",
    "\n",
    "However, CNNs require a fixed size for all inputs. To overcome this we will zero pad the output vectors to make them all the same size. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import soundfile as sf\n",
    "import librosa\n",
    "max_pad_len = 174\n",
    "\n",
    "def extract_features(file_name):\n",
    "   \n",
    "    try:\n",
    "        audio, sample_rate = librosa.load(file_name, res_type='kaiser_fast') \n",
    "        audio2 = audio*(2**15).astype(int16)\n",
    "        #mfccs = librosa.feature.mfcc(y=audio, sr=sample_rate, n_mfcc=40)\n",
    "        #pad_width = max_pad_len - mfccs.shape[1]\n",
    "        #mfccs = np.pad(mfccs, pad_width=((0, 0), (0, pad_width)), mode='constant')\n",
    "        #librosa.output.write_wav('gun_shot22.wav', audio, sample_rate)\n",
    "        sf.write('gun_shot22.wav', audio2, sample_rate, 'PCM_16')\n",
    "    except Exception as e:\n",
    "        print(\"Error encountered while parsing file: \", file_name)\n",
    "        return None \n",
    "     \n",
    "    return mfccs"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/yutonggu/.local/lib/python3.6/site-packages/librosa/core/audio.py:146: UserWarning: PySoundFile failed. Trying audioread instead.\n",
      "  warnings.warn('PySoundFile failed. Trying audioread instead.')\n",
      "/home/yutonggu/.local/lib/python3.6/site-packages/librosa/core/audio.py:146: UserWarning: PySoundFile failed. Trying audioread instead.\n",
      "  warnings.warn('PySoundFile failed. Trying audioread instead.')\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Error encountered while parsing file:  /Users/candre/Documents/UrbanSound8K/audio/fold5/100032-3-0-0.wav\n",
      "Error encountered while parsing file:  /Users/candre/Documents/UrbanSound8K/audio/fold5/100263-2-0-117.wav\n",
      "Error encountered while parsing file:  /Users/candre/Documents/UrbanSound8K/audio/fold5/100263-2-0-121.wav\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/yutonggu/.local/lib/python3.6/site-packages/librosa/core/audio.py:146: UserWarning: PySoundFile failed. Trying audioread instead.\n",
      "  warnings.warn('PySoundFile failed. Trying audioread instead.')\n",
      "/home/yutonggu/.local/lib/python3.6/site-packages/librosa/core/audio.py:146: UserWarning: PySoundFile failed. Trying audioread instead.\n",
      "  warnings.warn('PySoundFile failed. Trying audioread instead.')\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Error encountered while parsing file:  /Users/candre/Documents/UrbanSound8K/audio/fold5/100263-2-0-126.wav\n",
      "Error encountered while parsing file:  /Users/candre/Documents/UrbanSound8K/audio/fold5/100263-2-0-137.wav\n",
      "Error encountered while parsing file:  /Users/candre/Documents/UrbanSound8K/audio/fold5/100263-2-0-143.wav\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/yutonggu/.local/lib/python3.6/site-packages/librosa/core/audio.py:146: UserWarning: PySoundFile failed. Trying audioread instead.\n",
      "  warnings.warn('PySoundFile failed. Trying audioread instead.')\n",
      "/home/yutonggu/.local/lib/python3.6/site-packages/librosa/core/audio.py:146: UserWarning: PySoundFile failed. Trying audioread instead.\n",
      "  warnings.warn('PySoundFile failed. Trying audioread instead.')\n",
      "/home/yutonggu/.local/lib/python3.6/site-packages/librosa/core/audio.py:146: UserWarning: PySoundFile failed. Trying audioread instead.\n",
      "  warnings.warn('PySoundFile failed. Trying audioread instead.')\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Error encountered while parsing file:  /Users/candre/Documents/UrbanSound8K/audio/fold5/100263-2-0-161.wav\n",
      "Error encountered while parsing file:  /Users/candre/Documents/UrbanSound8K/audio/fold5/100263-2-0-3.wav\n",
      "Error encountered while parsing file:  /Users/candre/Documents/UrbanSound8K/audio/fold5/100263-2-0-36.wav\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/yutonggu/.local/lib/python3.6/site-packages/librosa/core/audio.py:146: UserWarning: PySoundFile failed. Trying audioread instead.\n",
      "  warnings.warn('PySoundFile failed. Trying audioread instead.')\n",
      "/home/yutonggu/.local/lib/python3.6/site-packages/librosa/core/audio.py:146: UserWarning: PySoundFile failed. Trying audioread instead.\n",
      "  warnings.warn('PySoundFile failed. Trying audioread instead.')\n",
      "/home/yutonggu/.local/lib/python3.6/site-packages/librosa/core/audio.py:146: UserWarning: PySoundFile failed. Trying audioread instead.\n",
      "  warnings.warn('PySoundFile failed. Trying audioread instead.')\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Error encountered while parsing file:  /Users/candre/Documents/UrbanSound8K/audio/fold10/100648-1-0-0.wav\n",
      "Error encountered while parsing file:  /Users/candre/Documents/UrbanSound8K/audio/fold10/100648-1-1-0.wav\n",
      "Error encountered while parsing file:  /Users/candre/Documents/UrbanSound8K/audio/fold10/100648-1-2-0.wav\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/yutonggu/.local/lib/python3.6/site-packages/librosa/core/audio.py:146: UserWarning: PySoundFile failed. Trying audioread instead.\n",
      "  warnings.warn('PySoundFile failed. Trying audioread instead.')\n",
      "/home/yutonggu/.local/lib/python3.6/site-packages/librosa/core/audio.py:146: UserWarning: PySoundFile failed. Trying audioread instead.\n",
      "  warnings.warn('PySoundFile failed. Trying audioread instead.')\n",
      "/home/yutonggu/.local/lib/python3.6/site-packages/librosa/core/audio.py:146: UserWarning: PySoundFile failed. Trying audioread instead.\n",
      "  warnings.warn('PySoundFile failed. Trying audioread instead.')\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Error encountered while parsing file:  /Users/candre/Documents/UrbanSound8K/audio/fold10/100648-1-3-0.wav\n",
      "Error encountered while parsing file:  /Users/candre/Documents/UrbanSound8K/audio/fold10/100648-1-4-0.wav\n",
      "Error encountered while parsing file:  /Users/candre/Documents/UrbanSound8K/audio/fold2/100652-3-0-0.wav\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/yutonggu/.local/lib/python3.6/site-packages/librosa/core/audio.py:146: UserWarning: PySoundFile failed. Trying audioread instead.\n",
      "  warnings.warn('PySoundFile failed. Trying audioread instead.')\n",
      "/home/yutonggu/.local/lib/python3.6/site-packages/librosa/core/audio.py:146: UserWarning: PySoundFile failed. Trying audioread instead.\n",
      "  warnings.warn('PySoundFile failed. Trying audioread instead.')\n",
      "/home/yutonggu/.local/lib/python3.6/site-packages/librosa/core/audio.py:146: UserWarning: PySoundFile failed. Trying audioread instead.\n",
      "  warnings.warn('PySoundFile failed. Trying audioread instead.')\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Error encountered while parsing file:  /Users/candre/Documents/UrbanSound8K/audio/fold2/100652-3-0-1.wav\n",
      "Error encountered while parsing file:  /Users/candre/Documents/UrbanSound8K/audio/fold2/100652-3-0-2.wav\n",
      "Error encountered while parsing file:  /Users/candre/Documents/UrbanSound8K/audio/fold2/100652-3-0-3.wav\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/yutonggu/.local/lib/python3.6/site-packages/librosa/core/audio.py:146: UserWarning: PySoundFile failed. Trying audioread instead.\n",
      "  warnings.warn('PySoundFile failed. Trying audioread instead.')\n",
      "/home/yutonggu/.local/lib/python3.6/site-packages/librosa/core/audio.py:146: UserWarning: PySoundFile failed. Trying audioread instead.\n",
      "  warnings.warn('PySoundFile failed. Trying audioread instead.')\n",
      "/home/yutonggu/.local/lib/python3.6/site-packages/librosa/core/audio.py:146: UserWarning: PySoundFile failed. Trying audioread instead.\n",
      "  warnings.warn('PySoundFile failed. Trying audioread instead.')\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Error encountered while parsing file:  /Users/candre/Documents/UrbanSound8K/audio/fold10/100795-3-0-0.wav\n",
      "Error encountered while parsing file:  /Users/candre/Documents/UrbanSound8K/audio/fold10/100795-3-1-0.wav\n",
      "Error encountered while parsing file:  /Users/candre/Documents/UrbanSound8K/audio/fold10/100795-3-1-1.wav\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/yutonggu/.local/lib/python3.6/site-packages/librosa/core/audio.py:146: UserWarning: PySoundFile failed. Trying audioread instead.\n",
      "  warnings.warn('PySoundFile failed. Trying audioread instead.')\n",
      "/home/yutonggu/.local/lib/python3.6/site-packages/librosa/core/audio.py:146: UserWarning: PySoundFile failed. Trying audioread instead.\n",
      "  warnings.warn('PySoundFile failed. Trying audioread instead.')\n",
      "/home/yutonggu/.local/lib/python3.6/site-packages/librosa/core/audio.py:146: UserWarning: PySoundFile failed. Trying audioread instead.\n",
      "  warnings.warn('PySoundFile failed. Trying audioread instead.')\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Error encountered while parsing file:  /Users/candre/Documents/UrbanSound8K/audio/fold10/100795-3-1-2.wav\n",
      "Error encountered while parsing file:  /Users/candre/Documents/UrbanSound8K/audio/fold5/100852-0-0-0.wav\n",
      "Error encountered while parsing file:  /Users/candre/Documents/UrbanSound8K/audio/fold5/100852-0-0-1.wav\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/yutonggu/.local/lib/python3.6/site-packages/librosa/core/audio.py:146: UserWarning: PySoundFile failed. Trying audioread instead.\n",
      "  warnings.warn('PySoundFile failed. Trying audioread instead.')\n",
      "/home/yutonggu/.local/lib/python3.6/site-packages/librosa/core/audio.py:146: UserWarning: PySoundFile failed. Trying audioread instead.\n",
      "  warnings.warn('PySoundFile failed. Trying audioread instead.')\n",
      "/home/yutonggu/.local/lib/python3.6/site-packages/librosa/core/audio.py:146: UserWarning: PySoundFile failed. Trying audioread instead.\n",
      "  warnings.warn('PySoundFile failed. Trying audioread instead.')\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Error encountered while parsing file:  /Users/candre/Documents/UrbanSound8K/audio/fold5/100852-0-0-10.wav\n",
      "Error encountered while parsing file:  /Users/candre/Documents/UrbanSound8K/audio/fold5/100852-0-0-11.wav\n",
      "Error encountered while parsing file:  /Users/candre/Documents/UrbanSound8K/audio/fold5/100852-0-0-12.wav\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/yutonggu/.local/lib/python3.6/site-packages/librosa/core/audio.py:146: UserWarning: PySoundFile failed. Trying audioread instead.\n",
      "  warnings.warn('PySoundFile failed. Trying audioread instead.')\n",
      "/home/yutonggu/.local/lib/python3.6/site-packages/librosa/core/audio.py:146: UserWarning: PySoundFile failed. Trying audioread instead.\n",
      "  warnings.warn('PySoundFile failed. Trying audioread instead.')\n",
      "/home/yutonggu/.local/lib/python3.6/site-packages/librosa/core/audio.py:146: UserWarning: PySoundFile failed. Trying audioread instead.\n",
      "  warnings.warn('PySoundFile failed. Trying audioread instead.')\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Error encountered while parsing file:  /Users/candre/Documents/UrbanSound8K/audio/fold5/100852-0-0-13.wav\n",
      "Error encountered while parsing file:  /Users/candre/Documents/UrbanSound8K/audio/fold5/100852-0-0-14.wav\n",
      "Error encountered while parsing file:  /Users/candre/Documents/UrbanSound8K/audio/fold5/100852-0-0-15.wav\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/yutonggu/.local/lib/python3.6/site-packages/librosa/core/audio.py:146: UserWarning: PySoundFile failed. Trying audioread instead.\n",
      "  warnings.warn('PySoundFile failed. Trying audioread instead.')\n",
      "/home/yutonggu/.local/lib/python3.6/site-packages/librosa/core/audio.py:146: UserWarning: PySoundFile failed. Trying audioread instead.\n",
      "  warnings.warn('PySoundFile failed. Trying audioread instead.')\n",
      "/home/yutonggu/.local/lib/python3.6/site-packages/librosa/core/audio.py:146: UserWarning: PySoundFile failed. Trying audioread instead.\n",
      "  warnings.warn('PySoundFile failed. Trying audioread instead.')\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Error encountered while parsing file:  /Users/candre/Documents/UrbanSound8K/audio/fold5/100852-0-0-16.wav\n",
      "Error encountered while parsing file:  /Users/candre/Documents/UrbanSound8K/audio/fold5/100852-0-0-17.wav\n",
      "Error encountered while parsing file:  /Users/candre/Documents/UrbanSound8K/audio/fold5/100852-0-0-18.wav\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/yutonggu/.local/lib/python3.6/site-packages/librosa/core/audio.py:146: UserWarning: PySoundFile failed. Trying audioread instead.\n",
      "  warnings.warn('PySoundFile failed. Trying audioread instead.')\n",
      "/home/yutonggu/.local/lib/python3.6/site-packages/librosa/core/audio.py:146: UserWarning: PySoundFile failed. Trying audioread instead.\n",
      "  warnings.warn('PySoundFile failed. Trying audioread instead.')\n",
      "/home/yutonggu/.local/lib/python3.6/site-packages/librosa/core/audio.py:146: UserWarning: PySoundFile failed. Trying audioread instead.\n",
      "  warnings.warn('PySoundFile failed. Trying audioread instead.')\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Error encountered while parsing file:  /Users/candre/Documents/UrbanSound8K/audio/fold5/100852-0-0-19.wav\n",
      "Error encountered while parsing file:  /Users/candre/Documents/UrbanSound8K/audio/fold5/100852-0-0-2.wav\n",
      "Error encountered while parsing file:  /Users/candre/Documents/UrbanSound8K/audio/fold5/100852-0-0-20.wav\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/yutonggu/.local/lib/python3.6/site-packages/librosa/core/audio.py:146: UserWarning: PySoundFile failed. Trying audioread instead.\n",
      "  warnings.warn('PySoundFile failed. Trying audioread instead.')\n",
      "/home/yutonggu/.local/lib/python3.6/site-packages/librosa/core/audio.py:146: UserWarning: PySoundFile failed. Trying audioread instead.\n",
      "  warnings.warn('PySoundFile failed. Trying audioread instead.')\n",
      "/home/yutonggu/.local/lib/python3.6/site-packages/librosa/core/audio.py:146: UserWarning: PySoundFile failed. Trying audioread instead.\n",
      "  warnings.warn('PySoundFile failed. Trying audioread instead.')\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Error encountered while parsing file:  /Users/candre/Documents/UrbanSound8K/audio/fold5/100852-0-0-21.wav\n",
      "Error encountered while parsing file:  /Users/candre/Documents/UrbanSound8K/audio/fold5/100852-0-0-22.wav\n",
      "Error encountered while parsing file:  /Users/candre/Documents/UrbanSound8K/audio/fold5/100852-0-0-23.wav\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/yutonggu/.local/lib/python3.6/site-packages/librosa/core/audio.py:146: UserWarning: PySoundFile failed. Trying audioread instead.\n",
      "  warnings.warn('PySoundFile failed. Trying audioread instead.')\n",
      "/home/yutonggu/.local/lib/python3.6/site-packages/librosa/core/audio.py:146: UserWarning: PySoundFile failed. Trying audioread instead.\n",
      "  warnings.warn('PySoundFile failed. Trying audioread instead.')\n",
      "/home/yutonggu/.local/lib/python3.6/site-packages/librosa/core/audio.py:146: UserWarning: PySoundFile failed. Trying audioread instead.\n",
      "  warnings.warn('PySoundFile failed. Trying audioread instead.')\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Error encountered while parsing file:  /Users/candre/Documents/UrbanSound8K/audio/fold5/100852-0-0-24.wav\n",
      "Error encountered while parsing file:  /Users/candre/Documents/UrbanSound8K/audio/fold5/100852-0-0-25.wav\n",
      "Error encountered while parsing file:  /Users/candre/Documents/UrbanSound8K/audio/fold5/100852-0-0-26.wav\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/yutonggu/.local/lib/python3.6/site-packages/librosa/core/audio.py:146: UserWarning: PySoundFile failed. Trying audioread instead.\n",
      "  warnings.warn('PySoundFile failed. Trying audioread instead.')\n",
      "/home/yutonggu/.local/lib/python3.6/site-packages/librosa/core/audio.py:146: UserWarning: PySoundFile failed. Trying audioread instead.\n",
      "  warnings.warn('PySoundFile failed. Trying audioread instead.')\n",
      "/home/yutonggu/.local/lib/python3.6/site-packages/librosa/core/audio.py:146: UserWarning: PySoundFile failed. Trying audioread instead.\n",
      "  warnings.warn('PySoundFile failed. Trying audioread instead.')\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Error encountered while parsing file:  /Users/candre/Documents/UrbanSound8K/audio/fold5/100852-0-0-27.wav\n",
      "Error encountered while parsing file:  /Users/candre/Documents/UrbanSound8K/audio/fold5/100852-0-0-28.wav\n",
      "Error encountered while parsing file:  /Users/candre/Documents/UrbanSound8K/audio/fold5/100852-0-0-29.wav\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/yutonggu/.local/lib/python3.6/site-packages/librosa/core/audio.py:146: UserWarning: PySoundFile failed. Trying audioread instead.\n",
      "  warnings.warn('PySoundFile failed. Trying audioread instead.')\n",
      "/home/yutonggu/.local/lib/python3.6/site-packages/librosa/core/audio.py:146: UserWarning: PySoundFile failed. Trying audioread instead.\n",
      "  warnings.warn('PySoundFile failed. Trying audioread instead.')\n",
      "/home/yutonggu/.local/lib/python3.6/site-packages/librosa/core/audio.py:146: UserWarning: PySoundFile failed. Trying audioread instead.\n",
      "  warnings.warn('PySoundFile failed. Trying audioread instead.')\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Error encountered while parsing file:  /Users/candre/Documents/UrbanSound8K/audio/fold5/100852-0-0-3.wav\n",
      "Error encountered while parsing file:  /Users/candre/Documents/UrbanSound8K/audio/fold5/100852-0-0-30.wav\n",
      "Error encountered while parsing file:  /Users/candre/Documents/UrbanSound8K/audio/fold5/100852-0-0-4.wav\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/yutonggu/.local/lib/python3.6/site-packages/librosa/core/audio.py:146: UserWarning: PySoundFile failed. Trying audioread instead.\n",
      "  warnings.warn('PySoundFile failed. Trying audioread instead.')\n",
      "/home/yutonggu/.local/lib/python3.6/site-packages/librosa/core/audio.py:146: UserWarning: PySoundFile failed. Trying audioread instead.\n",
      "  warnings.warn('PySoundFile failed. Trying audioread instead.')\n",
      "/home/yutonggu/.local/lib/python3.6/site-packages/librosa/core/audio.py:146: UserWarning: PySoundFile failed. Trying audioread instead.\n",
      "  warnings.warn('PySoundFile failed. Trying audioread instead.')\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Error encountered while parsing file:  /Users/candre/Documents/UrbanSound8K/audio/fold5/100852-0-0-5.wav\n",
      "Error encountered while parsing file:  /Users/candre/Documents/UrbanSound8K/audio/fold5/100852-0-0-6.wav\n",
      "Error encountered while parsing file:  /Users/candre/Documents/UrbanSound8K/audio/fold5/100852-0-0-7.wav\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/yutonggu/.local/lib/python3.6/site-packages/librosa/core/audio.py:146: UserWarning: PySoundFile failed. Trying audioread instead.\n",
      "  warnings.warn('PySoundFile failed. Trying audioread instead.')\n",
      "/home/yutonggu/.local/lib/python3.6/site-packages/librosa/core/audio.py:146: UserWarning: PySoundFile failed. Trying audioread instead.\n",
      "  warnings.warn('PySoundFile failed. Trying audioread instead.')\n",
      "/home/yutonggu/.local/lib/python3.6/site-packages/librosa/core/audio.py:146: UserWarning: PySoundFile failed. Trying audioread instead.\n",
      "  warnings.warn('PySoundFile failed. Trying audioread instead.')\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Error encountered while parsing file:  /Users/candre/Documents/UrbanSound8K/audio/fold5/100852-0-0-8.wav\n",
      "Error encountered while parsing file:  /Users/candre/Documents/UrbanSound8K/audio/fold5/100852-0-0-9.wav\n",
      "Error encountered while parsing file:  /Users/candre/Documents/UrbanSound8K/audio/fold6/101281-3-0-0.wav\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/yutonggu/.local/lib/python3.6/site-packages/librosa/core/audio.py:146: UserWarning: PySoundFile failed. Trying audioread instead.\n",
      "  warnings.warn('PySoundFile failed. Trying audioread instead.')\n",
      "/home/yutonggu/.local/lib/python3.6/site-packages/librosa/core/audio.py:146: UserWarning: PySoundFile failed. Trying audioread instead.\n",
      "  warnings.warn('PySoundFile failed. Trying audioread instead.')\n",
      "/home/yutonggu/.local/lib/python3.6/site-packages/librosa/core/audio.py:146: UserWarning: PySoundFile failed. Trying audioread instead.\n",
      "  warnings.warn('PySoundFile failed. Trying audioread instead.')\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Error encountered while parsing file:  /Users/candre/Documents/UrbanSound8K/audio/fold6/101281-3-0-14.wav\n",
      "Error encountered while parsing file:  /Users/candre/Documents/UrbanSound8K/audio/fold6/101281-3-0-5.wav\n",
      "Error encountered while parsing file:  /Users/candre/Documents/UrbanSound8K/audio/fold10/101382-2-0-10.wav\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/yutonggu/.local/lib/python3.6/site-packages/librosa/core/audio.py:146: UserWarning: PySoundFile failed. Trying audioread instead.\n",
      "  warnings.warn('PySoundFile failed. Trying audioread instead.')\n",
      "/home/yutonggu/.local/lib/python3.6/site-packages/librosa/core/audio.py:146: UserWarning: PySoundFile failed. Trying audioread instead.\n",
      "  warnings.warn('PySoundFile failed. Trying audioread instead.')\n",
      "/home/yutonggu/.local/lib/python3.6/site-packages/librosa/core/audio.py:146: UserWarning: PySoundFile failed. Trying audioread instead.\n",
      "  warnings.warn('PySoundFile failed. Trying audioread instead.')\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Error encountered while parsing file:  /Users/candre/Documents/UrbanSound8K/audio/fold10/101382-2-0-12.wav\n",
      "Error encountered while parsing file:  /Users/candre/Documents/UrbanSound8K/audio/fold10/101382-2-0-20.wav\n",
      "Error encountered while parsing file:  /Users/candre/Documents/UrbanSound8K/audio/fold10/101382-2-0-21.wav\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/yutonggu/.local/lib/python3.6/site-packages/librosa/core/audio.py:146: UserWarning: PySoundFile failed. Trying audioread instead.\n",
      "  warnings.warn('PySoundFile failed. Trying audioread instead.')\n",
      "/home/yutonggu/.local/lib/python3.6/site-packages/librosa/core/audio.py:146: UserWarning: PySoundFile failed. Trying audioread instead.\n",
      "  warnings.warn('PySoundFile failed. Trying audioread instead.')\n",
      "/home/yutonggu/.local/lib/python3.6/site-packages/librosa/core/audio.py:146: UserWarning: PySoundFile failed. Trying audioread instead.\n",
      "  warnings.warn('PySoundFile failed. Trying audioread instead.')\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Error encountered while parsing file:  /Users/candre/Documents/UrbanSound8K/audio/fold10/101382-2-0-29.wav\n",
      "Error encountered while parsing file:  /Users/candre/Documents/UrbanSound8K/audio/fold10/101382-2-0-33.wav\n",
      "Error encountered while parsing file:  /Users/candre/Documents/UrbanSound8K/audio/fold10/101382-2-0-42.wav\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/yutonggu/.local/lib/python3.6/site-packages/librosa/core/audio.py:146: UserWarning: PySoundFile failed. Trying audioread instead.\n",
      "  warnings.warn('PySoundFile failed. Trying audioread instead.')\n",
      "/home/yutonggu/.local/lib/python3.6/site-packages/librosa/core/audio.py:146: UserWarning: PySoundFile failed. Trying audioread instead.\n",
      "  warnings.warn('PySoundFile failed. Trying audioread instead.')\n",
      "/home/yutonggu/.local/lib/python3.6/site-packages/librosa/core/audio.py:146: UserWarning: PySoundFile failed. Trying audioread instead.\n",
      "  warnings.warn('PySoundFile failed. Trying audioread instead.')\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Error encountered while parsing file:  /Users/candre/Documents/UrbanSound8K/audio/fold10/101382-2-0-45.wav\n",
      "Error encountered while parsing file:  /Users/candre/Documents/UrbanSound8K/audio/fold1/101415-3-0-2.wav\n",
      "Error encountered while parsing file:  /Users/candre/Documents/UrbanSound8K/audio/fold1/101415-3-0-3.wav\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/yutonggu/.local/lib/python3.6/site-packages/librosa/core/audio.py:146: UserWarning: PySoundFile failed. Trying audioread instead.\n",
      "  warnings.warn('PySoundFile failed. Trying audioread instead.')\n",
      "/home/yutonggu/.local/lib/python3.6/site-packages/librosa/core/audio.py:146: UserWarning: PySoundFile failed. Trying audioread instead.\n",
      "  warnings.warn('PySoundFile failed. Trying audioread instead.')\n",
      "/home/yutonggu/.local/lib/python3.6/site-packages/librosa/core/audio.py:146: UserWarning: PySoundFile failed. Trying audioread instead.\n",
      "  warnings.warn('PySoundFile failed. Trying audioread instead.')\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Error encountered while parsing file:  /Users/candre/Documents/UrbanSound8K/audio/fold1/101415-3-0-8.wav\n",
      "Error encountered while parsing file:  /Users/candre/Documents/UrbanSound8K/audio/fold9/101729-0-0-1.wav\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/yutonggu/.local/lib/python3.6/site-packages/librosa/core/audio.py:146: UserWarning: PySoundFile failed. Trying audioread instead.\n",
      "  warnings.warn('PySoundFile failed. Trying audioread instead.')\n",
      "/home/yutonggu/.local/lib/python3.6/site-packages/librosa/core/audio.py:146: UserWarning: PySoundFile failed. Trying audioread instead.\n",
      "  warnings.warn('PySoundFile failed. Trying audioread instead.')\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Error encountered while parsing file:  /Users/candre/Documents/UrbanSound8K/audio/fold9/101729-0-0-11.wav\n",
      "Error encountered while parsing file:  /Users/candre/Documents/UrbanSound8K/audio/fold9/101729-0-0-12.wav\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/yutonggu/.local/lib/python3.6/site-packages/librosa/core/audio.py:146: UserWarning: PySoundFile failed. Trying audioread instead.\n",
      "  warnings.warn('PySoundFile failed. Trying audioread instead.')\n",
      "/home/yutonggu/.local/lib/python3.6/site-packages/librosa/core/audio.py:146: UserWarning: PySoundFile failed. Trying audioread instead.\n",
      "  warnings.warn('PySoundFile failed. Trying audioread instead.')\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Error encountered while parsing file:  /Users/candre/Documents/UrbanSound8K/audio/fold9/101729-0-0-13.wav\n",
      "Error encountered while parsing file:  /Users/candre/Documents/UrbanSound8K/audio/fold9/101729-0-0-14.wav\n",
      "Error encountered while parsing file:  /Users/candre/Documents/UrbanSound8K/audio/fold9/101729-0-0-16.wav\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/yutonggu/.local/lib/python3.6/site-packages/librosa/core/audio.py:146: UserWarning: PySoundFile failed. Trying audioread instead.\n",
      "  warnings.warn('PySoundFile failed. Trying audioread instead.')\n",
      "/home/yutonggu/.local/lib/python3.6/site-packages/librosa/core/audio.py:146: UserWarning: PySoundFile failed. Trying audioread instead.\n",
      "  warnings.warn('PySoundFile failed. Trying audioread instead.')\n",
      "/home/yutonggu/.local/lib/python3.6/site-packages/librosa/core/audio.py:146: UserWarning: PySoundFile failed. Trying audioread instead.\n",
      "  warnings.warn('PySoundFile failed. Trying audioread instead.')\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Error encountered while parsing file:  /Users/candre/Documents/UrbanSound8K/audio/fold9/101729-0-0-17.wav\n",
      "Error encountered while parsing file:  /Users/candre/Documents/UrbanSound8K/audio/fold9/101729-0-0-18.wav\n",
      "Error encountered while parsing file:  /Users/candre/Documents/UrbanSound8K/audio/fold9/101729-0-0-19.wav\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/yutonggu/.local/lib/python3.6/site-packages/librosa/core/audio.py:146: UserWarning: PySoundFile failed. Trying audioread instead.\n",
      "  warnings.warn('PySoundFile failed. Trying audioread instead.')\n",
      "/home/yutonggu/.local/lib/python3.6/site-packages/librosa/core/audio.py:146: UserWarning: PySoundFile failed. Trying audioread instead.\n",
      "  warnings.warn('PySoundFile failed. Trying audioread instead.')\n",
      "/home/yutonggu/.local/lib/python3.6/site-packages/librosa/core/audio.py:146: UserWarning: PySoundFile failed. Trying audioread instead.\n",
      "  warnings.warn('PySoundFile failed. Trying audioread instead.')\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Error encountered while parsing file:  /Users/candre/Documents/UrbanSound8K/audio/fold9/101729-0-0-21.wav\n",
      "Error encountered while parsing file:  /Users/candre/Documents/UrbanSound8K/audio/fold9/101729-0-0-22.wav\n",
      "Error encountered while parsing file:  /Users/candre/Documents/UrbanSound8K/audio/fold9/101729-0-0-23.wav\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/yutonggu/.local/lib/python3.6/site-packages/librosa/core/audio.py:146: UserWarning: PySoundFile failed. Trying audioread instead.\n",
      "  warnings.warn('PySoundFile failed. Trying audioread instead.')\n",
      "/home/yutonggu/.local/lib/python3.6/site-packages/librosa/core/audio.py:146: UserWarning: PySoundFile failed. Trying audioread instead.\n",
      "  warnings.warn('PySoundFile failed. Trying audioread instead.')\n",
      "/home/yutonggu/.local/lib/python3.6/site-packages/librosa/core/audio.py:146: UserWarning: PySoundFile failed. Trying audioread instead.\n",
      "  warnings.warn('PySoundFile failed. Trying audioread instead.')\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Error encountered while parsing file:  /Users/candre/Documents/UrbanSound8K/audio/fold9/101729-0-0-24.wav\n",
      "Error encountered while parsing file:  /Users/candre/Documents/UrbanSound8K/audio/fold9/101729-0-0-26.wav\n",
      "Error encountered while parsing file:  /Users/candre/Documents/UrbanSound8K/audio/fold9/101729-0-0-28.wav\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/yutonggu/.local/lib/python3.6/site-packages/librosa/core/audio.py:146: UserWarning: PySoundFile failed. Trying audioread instead.\n",
      "  warnings.warn('PySoundFile failed. Trying audioread instead.')\n",
      "/home/yutonggu/.local/lib/python3.6/site-packages/librosa/core/audio.py:146: UserWarning: PySoundFile failed. Trying audioread instead.\n",
      "  warnings.warn('PySoundFile failed. Trying audioread instead.')\n",
      "/home/yutonggu/.local/lib/python3.6/site-packages/librosa/core/audio.py:146: UserWarning: PySoundFile failed. Trying audioread instead.\n",
      "  warnings.warn('PySoundFile failed. Trying audioread instead.')\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Error encountered while parsing file:  /Users/candre/Documents/UrbanSound8K/audio/fold9/101729-0-0-29.wav\n",
      "Error encountered while parsing file:  /Users/candre/Documents/UrbanSound8K/audio/fold9/101729-0-0-3.wav\n",
      "Error encountered while parsing file:  /Users/candre/Documents/UrbanSound8K/audio/fold9/101729-0-0-32.wav\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/yutonggu/.local/lib/python3.6/site-packages/librosa/core/audio.py:146: UserWarning: PySoundFile failed. Trying audioread instead.\n",
      "  warnings.warn('PySoundFile failed. Trying audioread instead.')\n",
      "/home/yutonggu/.local/lib/python3.6/site-packages/librosa/core/audio.py:146: UserWarning: PySoundFile failed. Trying audioread instead.\n",
      "  warnings.warn('PySoundFile failed. Trying audioread instead.')\n",
      "/home/yutonggu/.local/lib/python3.6/site-packages/librosa/core/audio.py:146: UserWarning: PySoundFile failed. Trying audioread instead.\n",
      "  warnings.warn('PySoundFile failed. Trying audioread instead.')\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Error encountered while parsing file:  /Users/candre/Documents/UrbanSound8K/audio/fold9/101729-0-0-33.wav\n",
      "Error encountered while parsing file:  /Users/candre/Documents/UrbanSound8K/audio/fold9/101729-0-0-36.wav\n",
      "Error encountered while parsing file:  /Users/candre/Documents/UrbanSound8K/audio/fold9/101729-0-0-37.wav\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/yutonggu/.local/lib/python3.6/site-packages/librosa/core/audio.py:146: UserWarning: PySoundFile failed. Trying audioread instead.\n",
      "  warnings.warn('PySoundFile failed. Trying audioread instead.')\n",
      "/home/yutonggu/.local/lib/python3.6/site-packages/librosa/core/audio.py:146: UserWarning: PySoundFile failed. Trying audioread instead.\n",
      "  warnings.warn('PySoundFile failed. Trying audioread instead.')\n",
      "/home/yutonggu/.local/lib/python3.6/site-packages/librosa/core/audio.py:146: UserWarning: PySoundFile failed. Trying audioread instead.\n",
      "  warnings.warn('PySoundFile failed. Trying audioread instead.')\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Error encountered while parsing file:  /Users/candre/Documents/UrbanSound8K/audio/fold9/101729-0-0-38.wav\n",
      "Error encountered while parsing file:  /Users/candre/Documents/UrbanSound8K/audio/fold9/101729-0-0-39.wav\n",
      "Error encountered while parsing file:  /Users/candre/Documents/UrbanSound8K/audio/fold9/101729-0-0-4.wav\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/yutonggu/.local/lib/python3.6/site-packages/librosa/core/audio.py:146: UserWarning: PySoundFile failed. Trying audioread instead.\n",
      "  warnings.warn('PySoundFile failed. Trying audioread instead.')\n",
      "/home/yutonggu/.local/lib/python3.6/site-packages/librosa/core/audio.py:146: UserWarning: PySoundFile failed. Trying audioread instead.\n",
      "  warnings.warn('PySoundFile failed. Trying audioread instead.')\n",
      "/home/yutonggu/.local/lib/python3.6/site-packages/librosa/core/audio.py:146: UserWarning: PySoundFile failed. Trying audioread instead.\n",
      "  warnings.warn('PySoundFile failed. Trying audioread instead.')\n"
     ]
    },
    {
     "ename": "KeyboardInterrupt",
     "evalue": "",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mRuntimeError\u001b[0m                              Traceback (most recent call last)",
      "\u001b[0;32m~/.local/lib/python3.6/site-packages/librosa/core/audio.py\u001b[0m in \u001b[0;36mload\u001b[0;34m(path, sr, mono, offset, duration, dtype, res_type)\u001b[0m\n\u001b[1;32m    128\u001b[0m     \u001b[0;32mtry\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 129\u001b[0;31m         \u001b[0;32mwith\u001b[0m \u001b[0msf\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mSoundFile\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mpath\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;32mas\u001b[0m \u001b[0msf_desc\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    130\u001b[0m             \u001b[0msr_native\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0msf_desc\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0msamplerate\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/.local/lib/python3.6/site-packages/soundfile.py\u001b[0m in \u001b[0;36m__init__\u001b[0;34m(self, file, mode, samplerate, channels, subtype, endian, format, closefd)\u001b[0m\n\u001b[1;32m    626\u001b[0m                                          format, subtype, endian)\n\u001b[0;32m--> 627\u001b[0;31m         \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_file\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_open\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mfile\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mmode_int\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mclosefd\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    628\u001b[0m         \u001b[0;32mif\u001b[0m \u001b[0mset\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mmode\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0missuperset\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m'r+'\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;32mand\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mseekable\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/.local/lib/python3.6/site-packages/soundfile.py\u001b[0m in \u001b[0;36m_open\u001b[0;34m(self, file, mode_int, closefd)\u001b[0m\n\u001b[1;32m   1181\u001b[0m         _error_check(_snd.sf_error(file_ptr),\n\u001b[0;32m-> 1182\u001b[0;31m                      \"Error opening {0!r}: \".format(self.name))\n\u001b[0m\u001b[1;32m   1183\u001b[0m         \u001b[0;32mif\u001b[0m \u001b[0mmode_int\u001b[0m \u001b[0;34m==\u001b[0m \u001b[0m_snd\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mSFM_WRITE\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/.local/lib/python3.6/site-packages/soundfile.py\u001b[0m in \u001b[0;36m_error_check\u001b[0;34m(err, prefix)\u001b[0m\n\u001b[1;32m   1354\u001b[0m         \u001b[0merr_str\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0m_snd\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0msf_error_number\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0merr\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 1355\u001b[0;31m         \u001b[0;32mraise\u001b[0m \u001b[0mRuntimeError\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mprefix\u001b[0m \u001b[0;34m+\u001b[0m \u001b[0m_ffi\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mstring\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0merr_str\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mdecode\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m'utf-8'\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m'replace'\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   1356\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;31mRuntimeError\u001b[0m: Error opening '/Users/candre/Documents/UrbanSound8K/audio/fold9/101729-0-0-40.wav': System error.",
      "\nDuring handling of the above exception, another exception occurred:\n",
      "\u001b[0;31mKeyboardInterrupt\u001b[0m                         Traceback (most recent call last)",
      "\u001b[0;32m<ipython-input-3-8e7974758880>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m\u001b[0m\n\u001b[1;32m     17\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     18\u001b[0m     \u001b[0mclass_label\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mrow\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m\"class_name\"\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 19\u001b[0;31m     \u001b[0mdata\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mextract_features\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mfile_name\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     20\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     21\u001b[0m     \u001b[0mfeatures\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mappend\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0mdata\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mclass_label\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m<ipython-input-2-c757c2a2e138>\u001b[0m in \u001b[0;36mextract_features\u001b[0;34m(file_name)\u001b[0m\n\u001b[1;32m      6\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      7\u001b[0m     \u001b[0;32mtry\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m----> 8\u001b[0;31m         \u001b[0maudio\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0msample_rate\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mlibrosa\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mload\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mfile_name\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mres_type\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;34m'kaiser_fast'\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m      9\u001b[0m         \u001b[0maudio2\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0maudio\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;36m2\u001b[0m\u001b[0;34m**\u001b[0m\u001b[0;36m15\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mastype\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mint16\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     10\u001b[0m         \u001b[0;31m#mfccs = librosa.feature.mfcc(y=audio, sr=sample_rate, n_mfcc=40)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/.local/lib/python3.6/site-packages/librosa/core/audio.py\u001b[0m in \u001b[0;36mload\u001b[0;34m(path, sr, mono, offset, duration, dtype, res_type)\u001b[0m\n\u001b[1;32m    145\u001b[0m         \u001b[0;32mif\u001b[0m \u001b[0misinstance\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mpath\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0msix\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mstring_types\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    146\u001b[0m             \u001b[0mwarnings\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mwarn\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m'PySoundFile failed. Trying audioread instead.'\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 147\u001b[0;31m             \u001b[0my\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0msr_native\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0m__audioread_load\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mpath\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0moffset\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mduration\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mdtype\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    148\u001b[0m         \u001b[0;32melse\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    149\u001b[0m             \u001b[0msix\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mreraise\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0msys\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mexc_info\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/.local/lib/python3.6/site-packages/librosa/core/audio.py\u001b[0m in \u001b[0;36m__audioread_load\u001b[0;34m(path, offset, duration, dtype)\u001b[0m\n\u001b[1;32m    169\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    170\u001b[0m     \u001b[0my\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;34m[\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 171\u001b[0;31m     \u001b[0;32mwith\u001b[0m \u001b[0maudioread\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0maudio_open\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mpath\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;32mas\u001b[0m \u001b[0minput_file\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    172\u001b[0m         \u001b[0msr_native\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0minput_file\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0msamplerate\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    173\u001b[0m         \u001b[0mn_channels\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0minput_file\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mchannels\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/.local/lib/python3.6/site-packages/audioread/__init__.py\u001b[0m in \u001b[0;36maudio_open\u001b[0;34m(path, backends)\u001b[0m\n\u001b[1;32m    105\u001b[0m     \"\"\"\n\u001b[1;32m    106\u001b[0m     \u001b[0;32mif\u001b[0m \u001b[0mbackends\u001b[0m \u001b[0;32mis\u001b[0m \u001b[0;32mNone\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 107\u001b[0;31m         \u001b[0mbackends\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mavailable_backends\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    108\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    109\u001b[0m     \u001b[0;32mfor\u001b[0m \u001b[0mBackendClass\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mbackends\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/.local/lib/python3.6/site-packages/audioread/__init__.py\u001b[0m in \u001b[0;36mavailable_backends\u001b[0;34m()\u001b[0m\n\u001b[1;32m     84\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     85\u001b[0m     \u001b[0;31m# FFmpeg.\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 86\u001b[0;31m     \u001b[0;32mif\u001b[0m \u001b[0mffdec\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mavailable\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     87\u001b[0m         \u001b[0mresult\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mappend\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mffdec\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mFFmpegAudioFile\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     88\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/.local/lib/python3.6/site-packages/audioread/ffdec.py\u001b[0m in \u001b[0;36mavailable\u001b[0;34m()\u001b[0m\n\u001b[1;32m    113\u001b[0m         \u001b[0;32mreturn\u001b[0m \u001b[0;32mFalse\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    114\u001b[0m     \u001b[0;32melse\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 115\u001b[0;31m         \u001b[0mproc\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mwait\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    116\u001b[0m         \u001b[0;32mreturn\u001b[0m \u001b[0mproc\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mreturncode\u001b[0m \u001b[0;34m==\u001b[0m \u001b[0;36m0\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    117\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/usr/lib/python3.6/subprocess.py\u001b[0m in \u001b[0;36mwait\u001b[0;34m(self, timeout, endtime)\u001b[0m\n\u001b[1;32m   1475\u001b[0m                         \u001b[0;32mif\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mreturncode\u001b[0m \u001b[0;32mis\u001b[0m \u001b[0;32mnot\u001b[0m \u001b[0;32mNone\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1476\u001b[0m                             \u001b[0;32mbreak\u001b[0m  \u001b[0;31m# Another thread waited.\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 1477\u001b[0;31m                         \u001b[0;34m(\u001b[0m\u001b[0mpid\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0msts\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_try_wait\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;36m0\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   1478\u001b[0m                         \u001b[0;31m# Check the pid and loop as waitpid has been known to\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1479\u001b[0m                         \u001b[0;31m# return 0 even without WNOHANG in odd situations.\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/usr/lib/python3.6/subprocess.py\u001b[0m in \u001b[0;36m_try_wait\u001b[0;34m(self, wait_flags)\u001b[0m\n\u001b[1;32m   1422\u001b[0m             \u001b[0;34m\"\"\"All callers to this function MUST hold self._waitpid_lock.\"\"\"\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1423\u001b[0m             \u001b[0;32mtry\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 1424\u001b[0;31m                 \u001b[0;34m(\u001b[0m\u001b[0mpid\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0msts\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mos\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mwaitpid\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mpid\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mwait_flags\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   1425\u001b[0m             \u001b[0;32mexcept\u001b[0m \u001b[0mChildProcessError\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1426\u001b[0m                 \u001b[0;31m# This happens if SIGCLD is set to be ignored or waiting\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;31mKeyboardInterrupt\u001b[0m: "
     ]
    }
   ],
   "source": [
    "# Load various imports \n",
    "import pandas as pd\n",
    "import os\n",
    "\n",
    "\n",
    "# Set the path to the full UrbanSound dataset \n",
    "fulldatasetpath = '/Users/candre/Documents/UrbanSound8K/audio'\n",
    "\n",
    "metadata = pd.read_csv('../UrbanSound Dataset sample/metadata/UrbanSound8K.csv')\n",
    "\n",
    "features = []\n",
    "\n",
    "# Iterate through each sound file and extract the features \n",
    "for index, row in metadata.iterrows():\n",
    "    \n",
    "    file_name = os.path.join(os.path.abspath(fulldatasetpath),'fold'+str(row[\"fold\"])+'/',str(row[\"slice_file_name\"]))\n",
    "    \n",
    "    class_label = row[\"class_name\"]\n",
    "    data = extract_features(file_name)\n",
    "    \n",
    "    features.append([data, class_label])\n",
    "\n",
    "# Convert into a Panda dataframe \n",
    "featuresdf = pd.DataFrame(features, columns=['feature','class_label'])\n",
    "\n",
    "print('Finished feature extraction from ', len(featuresdf), ' files') "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.preprocessing import LabelEncoder\n",
    "from keras.utils import to_categorical\n",
    "\n",
    "# Convert features and corresponding classification labels into numpy arrays\n",
    "X = np.array(featuresdf.feature.tolist())\n",
    "y = np.array(featuresdf.class_label.tolist())\n",
    "\n",
    "# Encode the classification labels\n",
    "le = LabelEncoder()\n",
    "yy = to_categorical(le.fit_transform(y)) \n",
    "\n",
    "# split the dataset \n",
    "from sklearn.model_selection import train_test_split \n",
    "\n",
    "x_train, x_test, y_train, y_test = train_test_split(X, yy, test_size=0.2, random_state = 42)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Convolutional Neural Network (CNN) model architecture \n",
    "\n",
    "\n",
    "We will modify our model to be a Convolutional Neural Network (CNN) again using Keras and a Tensorflow backend. \n",
    "\n",
    "Again we will use a `sequential` model, starting with a simple model architecture, consisting of four `Conv2D` convolution layers, with our final output layer being a `dense` layer. \n",
    "\n",
    "The convolution layers are designed for feature detection. It works by sliding a filter window over the input and performing a matrix multiplication and storing the result in a feature map. This operation is known as a convolution. \n",
    "\n",
    "\n",
    "The `filter` parameter specifies the number of nodes in each layer. Each layer will increase in size from 16, 32, 64 to 128, while the `kernel_size` parameter specifies the size of the kernel window which in this case is 2 resulting in a 2x2 filter matrix. \n",
    "\n",
    "The first layer will receive the input shape of (40, 174, 1) where 40 is the number of MFCC's 174 is the number of frames taking padding into account and the 1 signifying that the audio is mono. \n",
    "\n",
    "The activation function we will be using for our convolutional layers is `ReLU` which is the same as our previous model. We will use a smaller `Dropout` value of 20% on our convolutional layers. \n",
    "\n",
    "Each convolutional layer has an associated pooling layer of `MaxPooling2D` type with the final convolutional layer having a `GlobalAveragePooling2D` type. The pooling layer is do reduce the dimensionality of the model (by reducing the parameters and subsquent computation requirements) which serves to shorten the training time and reduce overfitting. The Max Pooling type takes the maximum size for each window and the Global Average Pooling type takes the average which is suitable for feeding into our `dense` output layer.  \n",
    "\n",
    "Our output layer will have 10 nodes (num_labels) which matches the number of possible classifications. The activation is for our output layer is `softmax`. Softmax makes the output sum up to 1 so the output can be interpreted as probabilities. The model will then make its prediction based on which option has the highest probability."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "48615600\n"
     ]
    }
   ],
   "source": [
    "import numpy as np\n",
    "from keras.models import Sequential\n",
    "from keras.layers import Dense, Dropout, Activation, Flatten\n",
    "from keras.layers import Convolution2D, Conv2D, MaxPooling2D, GlobalAveragePooling2D\n",
    "from keras.optimizers import Adam\n",
    "from keras.utils import np_utils\n",
    "from sklearn import metrics \n",
    "\n",
    "\n",
    "num_rows = 40\n",
    "num_columns = 174\n",
    "num_channels = 1\n",
    "\n",
    "x_train = x_train.reshape(x_train.shape[0], num_rows, num_columns, num_channels)\n",
    "x_test = x_test.reshape(x_test.shape[0], num_rows, num_columns, num_channels)\n",
    "\n",
    "\n",
    "print(x_train.size)\n",
    "\n",
    "\n",
    "num_labels = yy.shape[1]\n",
    "filter_size = 2\n",
    "\n",
    "# Construct model \n",
    "model = Sequential()\n",
    "model.add(Conv2D(filters=16, kernel_size=2, input_shape=(num_rows, num_columns, num_channels), activation='relu'))\n",
    "model.add(MaxPooling2D(pool_size=2))\n",
    "model.add(Dropout(0.2))\n",
    "\n",
    "model.add(Conv2D(filters=32, kernel_size=2, activation='relu'))\n",
    "model.add(MaxPooling2D(pool_size=2))\n",
    "model.add(Dropout(0.2))\n",
    "\n",
    "model.add(Conv2D(filters=64, kernel_size=2, activation='relu'))\n",
    "model.add(MaxPooling2D(pool_size=2))\n",
    "model.add(Dropout(0.2))\n",
    "\n",
    "model.add(Conv2D(filters=128, kernel_size=2, activation='relu'))\n",
    "model.add(MaxPooling2D(pool_size=2))\n",
    "model.add(Dropout(0.2))\n",
    "model.add(GlobalAveragePooling2D())\n",
    "\n",
    "model.add(Dense(num_labels, activation='softmax')) "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Compiling the model \n",
    "\n",
    "For compiling our model, we will use the same three parameters as the previous model: "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Compile the model\n",
    "model.compile(loss='categorical_crossentropy', metrics=['accuracy'], optimizer='adam') "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model: \"sequential_6\"\n",
      "_________________________________________________________________\n",
      "Layer (type)                 Output Shape              Param #   \n",
      "=================================================================\n",
      "conv2d_21 (Conv2D)           (None, 39, 173, 16)       80        \n",
      "_________________________________________________________________\n",
      "max_pooling2d_21 (MaxPooling (None, 19, 86, 16)        0         \n",
      "_________________________________________________________________\n",
      "dropout_21 (Dropout)         (None, 19, 86, 16)        0         \n",
      "_________________________________________________________________\n",
      "conv2d_22 (Conv2D)           (None, 18, 85, 32)        2080      \n",
      "_________________________________________________________________\n",
      "max_pooling2d_22 (MaxPooling (None, 9, 42, 32)         0         \n",
      "_________________________________________________________________\n",
      "dropout_22 (Dropout)         (None, 9, 42, 32)         0         \n",
      "_________________________________________________________________\n",
      "conv2d_23 (Conv2D)           (None, 8, 41, 64)         8256      \n",
      "_________________________________________________________________\n",
      "max_pooling2d_23 (MaxPooling (None, 4, 20, 64)         0         \n",
      "_________________________________________________________________\n",
      "dropout_23 (Dropout)         (None, 4, 20, 64)         0         \n",
      "_________________________________________________________________\n",
      "conv2d_24 (Conv2D)           (None, 3, 19, 128)        32896     \n",
      "_________________________________________________________________\n",
      "max_pooling2d_24 (MaxPooling (None, 1, 9, 128)         0         \n",
      "_________________________________________________________________\n",
      "dropout_24 (Dropout)         (None, 1, 9, 128)         0         \n",
      "_________________________________________________________________\n",
      "global_average_pooling2d_6 ( (None, 128)               0         \n",
      "_________________________________________________________________\n",
      "dense_6 (Dense)              (None, 10)                1290      \n",
      "=================================================================\n",
      "Total params: 44,602\n",
      "Trainable params: 44,602\n",
      "Non-trainable params: 0\n",
      "_________________________________________________________________\n",
      "1747/1747 [==============================] - 1s 345us/step\n",
      "Pre-training accuracy: 11.5054%\n"
     ]
    }
   ],
   "source": [
    "# Display model architecture summary \n",
    "model.summary()\n",
    "\n",
    "# Calculate pre-training accuracy \n",
    "score = model.evaluate(x_test, y_test, verbose=1)\n",
    "accuracy = 100*score[1]\n",
    "\n",
    "print(\"Pre-training accuracy: %.4f%%\" % accuracy)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Training \n",
    "\n",
    "Here we will train the model. As training a CNN can take a sigificant amount of time, we will start with a low number of epochs and a low batch size. If we can see from the output that the model is converging, we will increase both numbers.  "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train on 6985 samples, validate on 1747 samples\n",
      "Epoch 1/70\n",
      "6985/6985 [==============================] - 13s 2ms/step - loss: 5.1447 - accuracy: 0.1705 - val_loss: 2.1515 - val_accuracy: 0.2244\n",
      "\n",
      "Epoch 00001: val_loss improved from inf to 2.15150, saving model to saved_models/weights.best.basic_cnn.hdf5\n",
      "Epoch 2/70\n",
      "6985/6985 [==============================] - 12s 2ms/step - loss: 1.9830 - accuracy: 0.2792 - val_loss: 1.9697 - val_accuracy: 0.3205\n",
      "\n",
      "Epoch 00002: val_loss improved from 2.15150 to 1.96969, saving model to saved_models/weights.best.basic_cnn.hdf5\n",
      "Epoch 3/70\n",
      "6985/6985 [==============================] - 13s 2ms/step - loss: 1.6967 - accuracy: 0.3920 - val_loss: 1.7337 - val_accuracy: 0.4116\n",
      "\n",
      "Epoch 00003: val_loss improved from 1.96969 to 1.73369, saving model to saved_models/weights.best.basic_cnn.hdf5\n",
      "Epoch 4/70\n",
      "6985/6985 [==============================] - 12s 2ms/step - loss: 1.5151 - accuracy: 0.4553 - val_loss: 1.5585 - val_accuracy: 0.4923\n",
      "\n",
      "Epoch 00004: val_loss improved from 1.73369 to 1.55845, saving model to saved_models/weights.best.basic_cnn.hdf5\n",
      "Epoch 5/70\n",
      "6985/6985 [==============================] - 12s 2ms/step - loss: 1.3902 - accuracy: 0.5104 - val_loss: 1.4544 - val_accuracy: 0.5341\n",
      "\n",
      "Epoch 00005: val_loss improved from 1.55845 to 1.45439, saving model to saved_models/weights.best.basic_cnn.hdf5\n",
      "Epoch 6/70\n",
      "6985/6985 [==============================] - 13s 2ms/step - loss: 1.3107 - accuracy: 0.5343 - val_loss: 1.3641 - val_accuracy: 0.5621\n",
      "\n",
      "Epoch 00006: val_loss improved from 1.45439 to 1.36412, saving model to saved_models/weights.best.basic_cnn.hdf5\n",
      "Epoch 7/70\n",
      "6985/6985 [==============================] - 13s 2ms/step - loss: 1.2545 - accuracy: 0.5612 - val_loss: 1.3414 - val_accuracy: 0.5781\n",
      "\n",
      "Epoch 00007: val_loss improved from 1.36412 to 1.34143, saving model to saved_models/weights.best.basic_cnn.hdf5\n",
      "Epoch 8/70\n",
      "6985/6985 [==============================] - 12s 2ms/step - loss: 1.1900 - accuracy: 0.5812 - val_loss: 1.2574 - val_accuracy: 0.6176\n",
      "\n",
      "Epoch 00008: val_loss improved from 1.34143 to 1.25736, saving model to saved_models/weights.best.basic_cnn.hdf5\n",
      "Epoch 9/70\n",
      "6985/6985 [==============================] - 12s 2ms/step - loss: 1.1313 - accuracy: 0.6047 - val_loss: 1.2088 - val_accuracy: 0.6142\n",
      "\n",
      "Epoch 00009: val_loss improved from 1.25736 to 1.20881, saving model to saved_models/weights.best.basic_cnn.hdf5\n",
      "Epoch 10/70\n",
      "6985/6985 [==============================] - 12s 2ms/step - loss: 1.0726 - accuracy: 0.6186 - val_loss: 1.1630 - val_accuracy: 0.6142\n",
      "\n",
      "Epoch 00010: val_loss improved from 1.20881 to 1.16299, saving model to saved_models/weights.best.basic_cnn.hdf5\n",
      "Epoch 11/70\n",
      "6985/6985 [==============================] - 13s 2ms/step - loss: 1.0299 - accuracy: 0.6464 - val_loss: 1.1401 - val_accuracy: 0.6228\n",
      "\n",
      "Epoch 00011: val_loss improved from 1.16299 to 1.14015, saving model to saved_models/weights.best.basic_cnn.hdf5\n",
      "Epoch 12/70\n",
      "6985/6985 [==============================] - 13s 2ms/step - loss: 1.0043 - accuracy: 0.6564 - val_loss: 1.0811 - val_accuracy: 0.6508\n",
      "\n",
      "Epoch 00012: val_loss improved from 1.14015 to 1.08108, saving model to saved_models/weights.best.basic_cnn.hdf5\n",
      "Epoch 13/70\n",
      "6985/6985 [==============================] - 13s 2ms/step - loss: 0.9649 - accuracy: 0.6626 - val_loss: 1.0456 - val_accuracy: 0.6714\n",
      "\n",
      "Epoch 00013: val_loss improved from 1.08108 to 1.04562, saving model to saved_models/weights.best.basic_cnn.hdf5\n",
      "Epoch 14/70\n",
      "6985/6985 [==============================] - 13s 2ms/step - loss: 0.9276 - accuracy: 0.6842 - val_loss: 0.9925 - val_accuracy: 0.6863\n",
      "\n",
      "Epoch 00014: val_loss improved from 1.04562 to 0.99245, saving model to saved_models/weights.best.basic_cnn.hdf5\n",
      "Epoch 15/70\n",
      "6985/6985 [==============================] - 13s 2ms/step - loss: 0.9007 - accuracy: 0.6899 - val_loss: 0.9784 - val_accuracy: 0.6737\n",
      "\n",
      "Epoch 00015: val_loss improved from 0.99245 to 0.97845, saving model to saved_models/weights.best.basic_cnn.hdf5\n",
      "Epoch 16/70\n",
      "6985/6985 [==============================] - 13s 2ms/step - loss: 0.8452 - accuracy: 0.7107 - val_loss: 0.9557 - val_accuracy: 0.6863\n",
      "\n",
      "Epoch 00016: val_loss improved from 0.97845 to 0.95574, saving model to saved_models/weights.best.basic_cnn.hdf5\n",
      "Epoch 17/70\n",
      "6985/6985 [==============================] - 13s 2ms/step - loss: 0.8369 - accuracy: 0.7077 - val_loss: 0.9161 - val_accuracy: 0.6955\n",
      "\n",
      "Epoch 00017: val_loss improved from 0.95574 to 0.91612, saving model to saved_models/weights.best.basic_cnn.hdf5\n",
      "Epoch 18/70\n",
      "6985/6985 [==============================] - 12s 2ms/step - loss: 0.8157 - accuracy: 0.7208 - val_loss: 0.8971 - val_accuracy: 0.7132\n",
      "\n",
      "Epoch 00018: val_loss improved from 0.91612 to 0.89707, saving model to saved_models/weights.best.basic_cnn.hdf5\n",
      "Epoch 19/70\n",
      "6985/6985 [==============================] - 12s 2ms/step - loss: 0.7783 - accuracy: 0.7359 - val_loss: 0.8949 - val_accuracy: 0.7161\n",
      "\n",
      "Epoch 00019: val_loss improved from 0.89707 to 0.89490, saving model to saved_models/weights.best.basic_cnn.hdf5\n",
      "Epoch 20/70\n",
      "6985/6985 [==============================] - 12s 2ms/step - loss: 0.7669 - accuracy: 0.7387 - val_loss: 0.7995 - val_accuracy: 0.7590\n",
      "\n",
      "Epoch 00020: val_loss improved from 0.89490 to 0.79952, saving model to saved_models/weights.best.basic_cnn.hdf5\n",
      "Epoch 21/70\n",
      "6985/6985 [==============================] - 12s 2ms/step - loss: 0.7427 - accuracy: 0.7483 - val_loss: 0.7777 - val_accuracy: 0.7659\n",
      "\n",
      "Epoch 00021: val_loss improved from 0.79952 to 0.77769, saving model to saved_models/weights.best.basic_cnn.hdf5\n",
      "Epoch 22/70\n",
      "6985/6985 [==============================] - 12s 2ms/step - loss: 0.7080 - accuracy: 0.7622 - val_loss: 0.7974 - val_accuracy: 0.7487\n",
      "\n",
      "Epoch 00022: val_loss did not improve from 0.77769\n",
      "Epoch 23/70\n",
      "6985/6985 [==============================] - 12s 2ms/step - loss: 0.7076 - accuracy: 0.7593 - val_loss: 0.7566 - val_accuracy: 0.7602\n",
      "\n",
      "Epoch 00023: val_loss improved from 0.77769 to 0.75661, saving model to saved_models/weights.best.basic_cnn.hdf5\n",
      "Epoch 24/70\n",
      "6985/6985 [==============================] - 13s 2ms/step - loss: 0.6820 - accuracy: 0.7699 - val_loss: 0.7379 - val_accuracy: 0.7579\n",
      "\n",
      "Epoch 00024: val_loss improved from 0.75661 to 0.73788, saving model to saved_models/weights.best.basic_cnn.hdf5\n",
      "Epoch 25/70\n",
      "6985/6985 [==============================] - 12s 2ms/step - loss: 0.6705 - accuracy: 0.7724 - val_loss: 0.7432 - val_accuracy: 0.7636\n",
      "\n",
      "Epoch 00025: val_loss did not improve from 0.73788\n",
      "Epoch 26/70\n",
      "6985/6985 [==============================] - 12s 2ms/step - loss: 0.6772 - accuracy: 0.7681 - val_loss: 0.7613 - val_accuracy: 0.7556\n",
      "\n",
      "Epoch 00026: val_loss did not improve from 0.73788\n",
      "Epoch 27/70\n",
      "6985/6985 [==============================] - 12s 2ms/step - loss: 0.6405 - accuracy: 0.7831 - val_loss: 0.6770 - val_accuracy: 0.7894\n",
      "\n",
      "Epoch 00027: val_loss improved from 0.73788 to 0.67703, saving model to saved_models/weights.best.basic_cnn.hdf5\n",
      "Epoch 28/70\n",
      "6985/6985 [==============================] - 13s 2ms/step - loss: 0.6191 - accuracy: 0.7923 - val_loss: 0.6407 - val_accuracy: 0.8002\n",
      "\n",
      "Epoch 00028: val_loss improved from 0.67703 to 0.64069, saving model to saved_models/weights.best.basic_cnn.hdf5\n",
      "Epoch 29/70\n",
      "6985/6985 [==============================] - 13s 2ms/step - loss: 0.6020 - accuracy: 0.8001 - val_loss: 0.6737 - val_accuracy: 0.7859\n",
      "\n",
      "Epoch 00029: val_loss did not improve from 0.64069\n",
      "Epoch 30/70\n",
      "6985/6985 [==============================] - 13s 2ms/step - loss: 0.5910 - accuracy: 0.7956 - val_loss: 0.6335 - val_accuracy: 0.8082\n",
      "\n",
      "Epoch 00030: val_loss improved from 0.64069 to 0.63345, saving model to saved_models/weights.best.basic_cnn.hdf5\n",
      "Epoch 31/70\n",
      "6985/6985 [==============================] - 12s 2ms/step - loss: 0.5781 - accuracy: 0.8023 - val_loss: 0.6302 - val_accuracy: 0.8065\n",
      "\n",
      "Epoch 00031: val_loss improved from 0.63345 to 0.63025, saving model to saved_models/weights.best.basic_cnn.hdf5\n",
      "Epoch 32/70\n",
      "6985/6985 [==============================] - 12s 2ms/step - loss: 0.5599 - accuracy: 0.8086 - val_loss: 0.6394 - val_accuracy: 0.7916\n",
      "\n",
      "Epoch 00032: val_loss did not improve from 0.63025\n",
      "Epoch 33/70\n",
      "6985/6985 [==============================] - 12s 2ms/step - loss: 0.5665 - accuracy: 0.8106 - val_loss: 0.5952 - val_accuracy: 0.8111\n",
      "\n",
      "Epoch 00033: val_loss improved from 0.63025 to 0.59518, saving model to saved_models/weights.best.basic_cnn.hdf5\n",
      "Epoch 34/70\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "6985/6985 [==============================] - 12s 2ms/step - loss: 0.5338 - accuracy: 0.8220 - val_loss: 0.5474 - val_accuracy: 0.8283\n",
      "\n",
      "Epoch 00034: val_loss improved from 0.59518 to 0.54740, saving model to saved_models/weights.best.basic_cnn.hdf5\n",
      "Epoch 35/70\n",
      "6985/6985 [==============================] - 12s 2ms/step - loss: 0.5223 - accuracy: 0.8209 - val_loss: 0.5908 - val_accuracy: 0.8117\n",
      "\n",
      "Epoch 00035: val_loss did not improve from 0.54740\n",
      "Epoch 36/70\n",
      "6985/6985 [==============================] - 12s 2ms/step - loss: 0.5211 - accuracy: 0.8289 - val_loss: 0.5555 - val_accuracy: 0.8243\n",
      "\n",
      "Epoch 00036: val_loss did not improve from 0.54740\n",
      "Epoch 37/70\n",
      "6985/6985 [==============================] - 12s 2ms/step - loss: 0.4979 - accuracy: 0.8296 - val_loss: 0.5522 - val_accuracy: 0.8231\n",
      "\n",
      "Epoch 00037: val_loss did not improve from 0.54740\n",
      "Epoch 38/70\n",
      "6985/6985 [==============================] - 12s 2ms/step - loss: 0.4871 - accuracy: 0.8365 - val_loss: 0.5320 - val_accuracy: 0.8323\n",
      "\n",
      "Epoch 00038: val_loss improved from 0.54740 to 0.53201, saving model to saved_models/weights.best.basic_cnn.hdf5\n",
      "Epoch 39/70\n",
      "6985/6985 [==============================] - 12s 2ms/step - loss: 0.5007 - accuracy: 0.8304 - val_loss: 0.5160 - val_accuracy: 0.8363\n",
      "\n",
      "Epoch 00039: val_loss improved from 0.53201 to 0.51595, saving model to saved_models/weights.best.basic_cnn.hdf5\n",
      "Epoch 40/70\n",
      "6985/6985 [==============================] - 13s 2ms/step - loss: 0.4706 - accuracy: 0.8361 - val_loss: 0.5110 - val_accuracy: 0.8420\n",
      "\n",
      "Epoch 00040: val_loss improved from 0.51595 to 0.51101, saving model to saved_models/weights.best.basic_cnn.hdf5\n",
      "Epoch 41/70\n",
      "6985/6985 [==============================] - 13s 2ms/step - loss: 0.4573 - accuracy: 0.8462 - val_loss: 0.5007 - val_accuracy: 0.8426\n",
      "\n",
      "Epoch 00041: val_loss improved from 0.51101 to 0.50074, saving model to saved_models/weights.best.basic_cnn.hdf5\n",
      "Epoch 42/70\n",
      "6985/6985 [==============================] - 12s 2ms/step - loss: 0.4521 - accuracy: 0.8448 - val_loss: 0.4862 - val_accuracy: 0.8443\n",
      "\n",
      "Epoch 00042: val_loss improved from 0.50074 to 0.48622, saving model to saved_models/weights.best.basic_cnn.hdf5\n",
      "Epoch 43/70\n",
      "6985/6985 [==============================] - 12s 2ms/step - loss: 0.4636 - accuracy: 0.8388 - val_loss: 0.5110 - val_accuracy: 0.8334\n",
      "\n",
      "Epoch 00043: val_loss did not improve from 0.48622\n",
      "Epoch 44/70\n",
      "6985/6985 [==============================] - 13s 2ms/step - loss: 0.4385 - accuracy: 0.8508 - val_loss: 0.5114 - val_accuracy: 0.8374\n",
      "\n",
      "Epoch 00044: val_loss did not improve from 0.48622\n",
      "Epoch 45/70\n",
      "6985/6985 [==============================] - 13s 2ms/step - loss: 0.4376 - accuracy: 0.8481 - val_loss: 0.5070 - val_accuracy: 0.8380\n",
      "\n",
      "Epoch 00045: val_loss did not improve from 0.48622\n",
      "Epoch 46/70\n",
      "6985/6985 [==============================] - 12s 2ms/step - loss: 0.4241 - accuracy: 0.8578 - val_loss: 0.4528 - val_accuracy: 0.8598\n",
      "\n",
      "Epoch 00046: val_loss improved from 0.48622 to 0.45277, saving model to saved_models/weights.best.basic_cnn.hdf5\n",
      "Epoch 47/70\n",
      "6985/6985 [==============================] - 12s 2ms/step - loss: 0.4130 - accuracy: 0.8593 - val_loss: 0.4673 - val_accuracy: 0.8500\n",
      "\n",
      "Epoch 00047: val_loss did not improve from 0.45277\n",
      "Epoch 48/70\n",
      "6985/6985 [==============================] - 12s 2ms/step - loss: 0.4039 - accuracy: 0.8623 - val_loss: 0.4436 - val_accuracy: 0.8620\n",
      "\n",
      "Epoch 00048: val_loss improved from 0.45277 to 0.44360, saving model to saved_models/weights.best.basic_cnn.hdf5\n",
      "Epoch 49/70\n",
      "6985/6985 [==============================] - 13s 2ms/step - loss: 0.4108 - accuracy: 0.8621 - val_loss: 0.4426 - val_accuracy: 0.8603\n",
      "\n",
      "Epoch 00049: val_loss improved from 0.44360 to 0.44263, saving model to saved_models/weights.best.basic_cnn.hdf5\n",
      "Epoch 50/70\n",
      "6985/6985 [==============================] - 13s 2ms/step - loss: 0.3878 - accuracy: 0.8684 - val_loss: 0.4404 - val_accuracy: 0.8580\n",
      "\n",
      "Epoch 00050: val_loss improved from 0.44263 to 0.44044, saving model to saved_models/weights.best.basic_cnn.hdf5\n",
      "Epoch 51/70\n",
      "6985/6985 [==============================] - 12s 2ms/step - loss: 0.3833 - accuracy: 0.8720 - val_loss: 0.4472 - val_accuracy: 0.8535\n",
      "\n",
      "Epoch 00051: val_loss did not improve from 0.44044\n",
      "Epoch 52/70\n",
      "6985/6985 [==============================] - 12s 2ms/step - loss: 0.3844 - accuracy: 0.8647 - val_loss: 0.4524 - val_accuracy: 0.8569\n",
      "\n",
      "Epoch 00052: val_loss did not improve from 0.44044\n",
      "Epoch 53/70\n",
      "6985/6985 [==============================] - 13s 2ms/step - loss: 0.3710 - accuracy: 0.8746 - val_loss: 0.4221 - val_accuracy: 0.8638\n",
      "\n",
      "Epoch 00053: val_loss improved from 0.44044 to 0.42210, saving model to saved_models/weights.best.basic_cnn.hdf5\n",
      "Epoch 54/70\n",
      "6985/6985 [==============================] - 12s 2ms/step - loss: 0.3686 - accuracy: 0.8730 - val_loss: 0.4147 - val_accuracy: 0.8615\n",
      "\n",
      "Epoch 00054: val_loss improved from 0.42210 to 0.41475, saving model to saved_models/weights.best.basic_cnn.hdf5\n",
      "Epoch 55/70\n",
      "6985/6985 [==============================] - 12s 2ms/step - loss: 0.3578 - accuracy: 0.8799 - val_loss: 0.4193 - val_accuracy: 0.8655\n",
      "\n",
      "Epoch 00055: val_loss did not improve from 0.41475\n",
      "Epoch 56/70\n",
      "6985/6985 [==============================] - 13s 2ms/step - loss: 0.3556 - accuracy: 0.8753 - val_loss: 0.4175 - val_accuracy: 0.8620\n",
      "\n",
      "Epoch 00056: val_loss did not improve from 0.41475\n",
      "Epoch 57/70\n",
      "6985/6985 [==============================] - 12s 2ms/step - loss: 0.3372 - accuracy: 0.8833 - val_loss: 0.3950 - val_accuracy: 0.8718\n",
      "\n",
      "Epoch 00057: val_loss improved from 0.41475 to 0.39495, saving model to saved_models/weights.best.basic_cnn.hdf5\n",
      "Epoch 58/70\n",
      "6985/6985 [==============================] - 12s 2ms/step - loss: 0.3340 - accuracy: 0.8832 - val_loss: 0.4035 - val_accuracy: 0.8689\n",
      "\n",
      "Epoch 00058: val_loss did not improve from 0.39495\n",
      "Epoch 59/70\n",
      "6985/6985 [==============================] - 12s 2ms/step - loss: 0.3539 - accuracy: 0.8799 - val_loss: 0.4462 - val_accuracy: 0.8489\n",
      "\n",
      "Epoch 00059: val_loss did not improve from 0.39495\n",
      "Epoch 60/70\n",
      "6985/6985 [==============================] - 12s 2ms/step - loss: 0.3306 - accuracy: 0.8856 - val_loss: 0.3828 - val_accuracy: 0.8741\n",
      "\n",
      "Epoch 00060: val_loss improved from 0.39495 to 0.38280, saving model to saved_models/weights.best.basic_cnn.hdf5\n",
      "Epoch 61/70\n",
      "6985/6985 [==============================] - 12s 2ms/step - loss: 0.3378 - accuracy: 0.8822 - val_loss: 0.3955 - val_accuracy: 0.8729\n",
      "\n",
      "Epoch 00061: val_loss did not improve from 0.38280\n",
      "Epoch 62/70\n",
      "6985/6985 [==============================] - 12s 2ms/step - loss: 0.3202 - accuracy: 0.8886 - val_loss: 0.4348 - val_accuracy: 0.8620\n",
      "\n",
      "Epoch 00062: val_loss did not improve from 0.38280\n",
      "Epoch 63/70\n",
      "6985/6985 [==============================] - 12s 2ms/step - loss: 0.3225 - accuracy: 0.8859 - val_loss: 0.3844 - val_accuracy: 0.8764\n",
      "\n",
      "Epoch 00063: val_loss did not improve from 0.38280\n",
      "Epoch 64/70\n",
      "6985/6985 [==============================] - 12s 2ms/step - loss: 0.3205 - accuracy: 0.8890 - val_loss: 0.3708 - val_accuracy: 0.8827\n",
      "\n",
      "Epoch 00064: val_loss improved from 0.38280 to 0.37082, saving model to saved_models/weights.best.basic_cnn.hdf5\n",
      "Epoch 65/70\n",
      "6985/6985 [==============================] - 12s 2ms/step - loss: 0.3049 - accuracy: 0.8951 - val_loss: 0.3707 - val_accuracy: 0.8809\n",
      "\n",
      "Epoch 00065: val_loss improved from 0.37082 to 0.37067, saving model to saved_models/weights.best.basic_cnn.hdf5\n",
      "Epoch 66/70\n",
      "6985/6985 [==============================] - 12s 2ms/step - loss: 0.2927 - accuracy: 0.9005 - val_loss: 0.3761 - val_accuracy: 0.8792\n",
      "\n",
      "Epoch 00066: val_loss did not improve from 0.37067\n",
      "Epoch 67/70\n",
      "6985/6985 [==============================] - 12s 2ms/step - loss: 0.2958 - accuracy: 0.8998 - val_loss: 0.3866 - val_accuracy: 0.8775\n",
      "\n",
      "Epoch 00067: val_loss did not improve from 0.37067\n",
      "Epoch 68/70\n",
      "6985/6985 [==============================] - 12s 2ms/step - loss: 0.3017 - accuracy: 0.8979 - val_loss: 0.3903 - val_accuracy: 0.8695\n",
      "\n",
      "Epoch 00068: val_loss did not improve from 0.37067\n",
      "Epoch 69/70\n",
      "6985/6985 [==============================] - 12s 2ms/step - loss: 0.2953 - accuracy: 0.8962 - val_loss: 0.3585 - val_accuracy: 0.8878\n",
      "\n",
      "Epoch 00069: val_loss improved from 0.37067 to 0.35851, saving model to saved_models/weights.best.basic_cnn.hdf5\n",
      "Epoch 70/70\n",
      "6985/6985 [==============================] - 12s 2ms/step - loss: 0.2864 - accuracy: 0.8978 - val_loss: 0.3510 - val_accuracy: 0.8855\n",
      "\n",
      "Epoch 00070: val_loss improved from 0.35851 to 0.35095, saving model to saved_models/weights.best.basic_cnn.hdf5\n",
      "('Training completed in time: ', datetime.timedelta(0, 873, 159176))\n"
     ]
    }
   ],
   "source": [
    "from keras.callbacks import ModelCheckpoint \n",
    "from datetime import datetime \n",
    "\n",
    "#num_epochs = 12\n",
    "#num_batch_size = 128\n",
    "\n",
    "num_epochs = 70\n",
    "num_batch_size = 256\n",
    "\n",
    "checkpointer = ModelCheckpoint(filepath='saved_models/weights.best.basic_cnn.hdf5', \n",
    "                               verbose=1, save_best_only=True)\n",
    "start = datetime.now()\n",
    "\n",
    "model.fit(x_train, y_train, batch_size=num_batch_size, epochs=num_epochs, validation_data=(x_test, y_test), callbacks=[checkpointer], verbose=1)\n",
    "\n",
    "\n",
    "duration = datetime.now() - start\n",
    "print(\"Training completed in time: \", duration)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Test the model \n",
    "\n",
    "Here we will review the accuracy of the model on both the training and test data sets. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "('Training Accuracy: ', 0.9371510148048401)\n",
      "('Testing Accuracy: ', 0.8855180144309998)\n"
     ]
    }
   ],
   "source": [
    "# Evaluating the model on the training and testing set\n",
    "score = model.evaluate(x_train, y_train, verbose=0)\n",
    "print(\"Training Accuracy: \", score[1])\n",
    "\n",
    "score = model.evaluate(x_test, y_test, verbose=0)\n",
    "print(\"Testing Accuracy: \", score[1])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The Training and Testing accuracy scores are both high and an increase on our initial model. Training accuracy has increased by ~6% and Testing accuracy has increased by ~4%. \n",
    "\n",
    "There is a marginal increase in the difference between the Training and Test scores (~6% compared to ~5% previously) though the difference remains low so the model has not suffered from overfitting. "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Predictions  \n",
    "\n",
    "Here we will modify our previous method for testing the models predictions on a specified audio .wav file. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 66,
   "metadata": {},
   "outputs": [],
   "source": [
    "import sys\n",
    "np.set_printoptions(threshold=sys.maxsize)\n",
    "def print_prediction(file_name):\n",
    "    prediction_feature = extract_features(file_name) \n",
    "    print(prediction_feature)\n",
    "    prediction_feature = prediction_feature.reshape(1, num_rows, num_columns, num_channels)\n",
    "    #print(prediction_feature)\n",
    "    predicted_vector = model.predict_classes(prediction_feature)\n",
    "    predicted_class = le.inverse_transform(predicted_vector) \n",
    "    print(\"The predicted class is:\", predicted_class[0], '\\n') \n",
    "    \n",
    "    predicted_proba_vector = model.predict_proba(prediction_feature) \n",
    "    predicted_proba = predicted_proba_vector[0]\n",
    "    for i in range(len(predicted_proba)): \n",
    "        category = le.inverse_transform(np.array([i]))\n",
    "        print(category[0], \"\\t\\t : \", format(predicted_proba[i], '.32f') )"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Validation \n",
    "\n",
    "#### Test with sample data \n",
    "\n",
    "As before we will verify the predictions using a subsection of the sample audio files we explored in the first notebook. We expect the bulk of these to be classified correctly. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "('The predicted class is:', 'air_conditioner', '\\n')\n",
      "('air_conditioner', '\\t\\t : ', '0.95708501338958740234375000000000')\n",
      "('car_horn', '\\t\\t : ', '0.00201115407980978488922119140625')\n",
      "('children_playing', '\\t\\t : ', '0.00061390333576127886772155761719')\n",
      "('dog_bark', '\\t\\t : ', '0.00046956146252341568470001220703')\n",
      "('drilling', '\\t\\t : ', '0.00232938118278980255126953125000')\n",
      "('engine_idling', '\\t\\t : ', '0.00064762606052681803703308105469')\n",
      "('gun_shot', '\\t\\t : ', '0.00144061760511249303817749023438')\n",
      "('jackhammer', '\\t\\t : ', '0.03391617536544799804687500000000')\n",
      "('siren', '\\t\\t : ', '0.00002013012272072955965995788574')\n",
      "('street_music', '\\t\\t : ', '0.00146656413562595844268798828125')\n"
     ]
    }
   ],
   "source": [
    "# Class: Air Conditioner\n",
    "\n",
    "filename = '../UrbanSound Dataset sample/audio/100852-0-0-0.wav' \n",
    "print_prediction(filename) "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "('The predicted class is:', 'drilling', '\\n')\n",
      "('air_conditioner', '\\t\\t : ', '0.00001505508316768100485205650330')\n",
      "('car_horn', '\\t\\t : ', '0.00150471390224993228912353515625')\n",
      "('children_playing', '\\t\\t : ', '0.00000166091558639891445636749268')\n",
      "('dog_bark', '\\t\\t : ', '0.00016364839393645524978637695312')\n",
      "('drilling', '\\t\\t : ', '0.99442249536514282226562500000000')\n",
      "('engine_idling', '\\t\\t : ', '0.00000024612080551378312520682812')\n",
      "('gun_shot', '\\t\\t : ', '0.00000003126977787815121700987220')\n",
      "('jackhammer', '\\t\\t : ', '0.00156728783622384071350097656250')\n",
      "('siren', '\\t\\t : ', '0.00000015589374413593759527429938')\n",
      "('street_music', '\\t\\t : ', '0.00232471409253776073455810546875')\n"
     ]
    }
   ],
   "source": [
    "# Class: Drilling\n",
    "\n",
    "filename = '../UrbanSound Dataset sample/audio/103199-4-0-0.wav'\n",
    "print_prediction(filename) "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "('The predicted class is:', 'street_music', '\\n')\n",
      "('air_conditioner', '\\t\\t : ', '0.00064082344761118292808532714844')\n",
      "('car_horn', '\\t\\t : ', '0.00071255624061450362205505371094')\n",
      "('children_playing', '\\t\\t : ', '0.12054918706417083740234375000000')\n",
      "('dog_bark', '\\t\\t : ', '0.00159605708904564380645751953125')\n",
      "('drilling', '\\t\\t : ', '0.00000854602785693714395165443420')\n",
      "('engine_idling', '\\t\\t : ', '0.00000492121853312710300087928772')\n",
      "('gun_shot', '\\t\\t : ', '0.00000000088503554485086510794645')\n",
      "('jackhammer', '\\t\\t : ', '0.00000112627230919315479695796967')\n",
      "('siren', '\\t\\t : ', '0.00029533522319979965686798095703')\n",
      "('street_music', '\\t\\t : ', '0.87619137763977050781250000000000')\n"
     ]
    }
   ],
   "source": [
    "# Class: Street music \n",
    "\n",
    "filename = '../UrbanSound Dataset sample/audio/101848-9-0-0.wav'\n",
    "print_prediction(filename) "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "('The predicted class is:', 'car_horn', '\\n')\n",
      "('air_conditioner', '\\t\\t : ', '0.00058966845972463488578796386719')\n",
      "('car_horn', '\\t\\t : ', '0.33561104536056518554687500000000')\n",
      "('children_playing', '\\t\\t : ', '0.00684245349839329719543457031250')\n",
      "('dog_bark', '\\t\\t : ', '0.22358825802803039550781250000000')\n",
      "('drilling', '\\t\\t : ', '0.12775631248950958251953125000000')\n",
      "('engine_idling', '\\t\\t : ', '0.00994171202182769775390625000000')\n",
      "('gun_shot', '\\t\\t : ', '0.23269656300544738769531250000000')\n",
      "('jackhammer', '\\t\\t : ', '0.04654442891478538513183593750000')\n",
      "('siren', '\\t\\t : ', '0.01504954695701599121093750000000')\n",
      "('street_music', '\\t\\t : ', '0.00138007453642785549163818359375')\n"
     ]
    }
   ],
   "source": [
    "# Class: Car Horn \n",
    "\n",
    "filename = '../UrbanSound Dataset sample/audio/100648-1-0-0.wav'\n",
    "print_prediction(filename) "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Observations \n",
    "\n",
    "We can see that the model performs well. \n",
    "\n",
    "Interestingly, car horn was again incorrectly classifed but this time as drilling - though the per class confidence shows it was a close decision between car horn with 26% confidence and drilling at 34% confidence.  "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Other audio\n",
    "\n",
    "Again we will further validate our model using a sample of various copyright free sounds that we not part of either our test or training data. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "('The predicted class is:', 'dog_bark', '\\n')\n",
      "('air_conditioner', '\\t\\t : ', '0.00025222732801921665668487548828')\n",
      "('car_horn', '\\t\\t : ', '0.01215456426143646240234375000000')\n",
      "('children_playing', '\\t\\t : ', '0.01036813110113143920898437500000')\n",
      "('dog_bark', '\\t\\t : ', '0.94571644067764282226562500000000')\n",
      "('drilling', '\\t\\t : ', '0.01611184328794479370117187500000')\n",
      "('engine_idling', '\\t\\t : ', '0.00211789412423968315124511718750')\n",
      "('gun_shot', '\\t\\t : ', '0.00647735735401511192321777343750')\n",
      "('jackhammer', '\\t\\t : ', '0.00105677649844437837600708007812')\n",
      "('siren', '\\t\\t : ', '0.00231027230620384216308593750000')\n",
      "('street_music', '\\t\\t : ', '0.00343450112268328666687011718750')\n"
     ]
    }
   ],
   "source": [
    "filename = '../Evaluation audio/dog_bark_1.wav'\n",
    "print_prediction(filename) "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "('The predicted class is:', 'jackhammer', '\\n')\n",
      "('air_conditioner', '\\t\\t : ', '0.00040033127879723906517028808594')\n",
      "('car_horn', '\\t\\t : ', '0.00000946074305829824879765510559')\n",
      "('children_playing', '\\t\\t : ', '0.00001180569051939528435468673706')\n",
      "('dog_bark', '\\t\\t : ', '0.00021108664805069565773010253906')\n",
      "('drilling', '\\t\\t : ', '0.00010486484097782522439956665039')\n",
      "('engine_idling', '\\t\\t : ', '0.00215723342262208461761474609375')\n",
      "('gun_shot', '\\t\\t : ', '0.00148435379378497600555419921875')\n",
      "('jackhammer', '\\t\\t : ', '0.99550276994705200195312500000000')\n",
      "('siren', '\\t\\t : ', '0.00011328583786962553858757019043')\n",
      "('street_music', '\\t\\t : ', '0.00000482335462947958149015903473')\n"
     ]
    }
   ],
   "source": [
    "filename = '../Evaluation audio/drilling_1.wav'\n",
    "\n",
    "print_prediction(filename) "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 76,
   "metadata": {
    "scrolled": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "('Error encountered while parsing file: ', '../Evaluation audio/gun_shot_1.wav')\n",
      "None\n"
     ]
    },
    {
     "ename": "AttributeError",
     "evalue": "'NoneType' object has no attribute 'reshape'",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mAttributeError\u001b[0m                            Traceback (most recent call last)",
      "\u001b[0;32m<ipython-input-76-05f2fc53b664>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m()\u001b[0m\n\u001b[1;32m      1\u001b[0m \u001b[0mfilename\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;34m'../Evaluation audio/gun_shot_1.wav'\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      2\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m----> 3\u001b[0;31m \u001b[0mprint_prediction\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mfilename\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m",
      "\u001b[0;32m<ipython-input-66-2c996bb5a317>\u001b[0m in \u001b[0;36mprint_prediction\u001b[0;34m(file_name)\u001b[0m\n\u001b[1;32m      4\u001b[0m     \u001b[0mprediction_feature\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mextract_features\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mfile_name\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      5\u001b[0m     \u001b[0;32mprint\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mprediction_feature\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m----> 6\u001b[0;31m     \u001b[0mprediction_feature\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mprediction_feature\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mreshape\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;36m1\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mnum_rows\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mnum_columns\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mnum_channels\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m      7\u001b[0m     \u001b[0;31m#print(prediction_feature)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      8\u001b[0m     \u001b[0mpredicted_vector\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mmodel\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mpredict_classes\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mprediction_feature\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;31mAttributeError\u001b[0m: 'NoneType' object has no attribute 'reshape'"
     ]
    }
   ],
   "source": [
    "filename = '../Evaluation audio/gun_shot_1.wav'\n",
    "\n",
    "print_prediction(filename) "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Error encountered while parsing file:  ../Evaluation audio/gun_shot_1.wav\n"
     ]
    }
   ],
   "source": [
    "extract_features('../Evaluation audio/gun_shot_1.wav')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 39,
   "metadata": {
    "scrolled": false
   },
   "outputs": [],
   "source": [
    "import pickle"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 40,
   "metadata": {},
   "outputs": [],
   "source": [
    "pickle_out = open(\"CNN_model.pickle\",\"wb\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 41,
   "metadata": {},
   "outputs": [],
   "source": [
    "pickle.dump(model, pickle_out)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 42,
   "metadata": {},
   "outputs": [],
   "source": [
    "pickle_out.close()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Observations \n",
    "\n",
    "The performance of our final model is very good and has generalised well, seeming to predict well when tested against new audio data. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.8"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
